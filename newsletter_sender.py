import os
import logging
from supabase import create_client
from dotenv import load_dotenv
import resend
import time
import difflib
from typing import List, Dict, Any, Optional
from collections import defaultdict
import requests
from datetime import datetime, timedelta

# Resend ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì„í¬íŠ¸ ì œê±°

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('newsletter_sender.log', encoding='utf-8')
    ]
)
logger = logging.getLogger('newsletter_sender')

# Load environment variables
load_dotenv()

# Initialize Resend
resend.api_key = os.getenv("RESEND_API_KEY")
if not resend.api_key:
    logger.error("RESEND_API_KEY not found in environment variables")
    raise ValueError("RESEND_API_KEY environment variable is required")

# Supabase ì„¤ì •
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

def fetch_todays_news() -> List[Dict[str, Any]]:
    """
    ìµœê·¼ 1ì‹œê°„ ì´ë‚´ì— ìƒì„±ëœ ë‰´ìŠ¤ë¥¼ Supabaseì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Returns:
        List[Dict[str, Any]]: ìµœê·¼ 3ì‹œê°„ ì´ë‚´ì˜ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸
    """
    logger.info("Fetching recent news from Supabase (last 3 three)...")
    
    try:
        # í˜„ì¬ ì‹œê°„ìœ¼ë¡œë¶€í„° 1ì‹œê°„ ì „ ì‹œê°„ ê³„ì‚° (KST ê¸°ì¤€)
        now = datetime.utcnow()
        three_hour_ago = now - timedelta(hours=3)

        # KST ì‹œê°„ëŒ€ë¥¼ ê³ ë ¤í•˜ì—¬ í¬ë§·íŒ… (YYYY-MM-DD HH:MM:SS)
        time_format = '%Y-%m-%d %H:%M:%S'
        three_hour_ago_str = three_hour_ago.strftime(time_format)
        current_time_str = now.strftime(time_format)
        
        logger.info(f"Querying news published between {three_hour_ago_str} and {current_time_str}")
        
        # pub_date í•„ë“œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœê·¼ 3ì‹œê°„ ì´ë‚´ ë°œí–‰ëœ ê¸°ì‚¬ ì¡°íšŒ
        response = supabase.table('ai_news') \
            .select('*') \
            .gte('created_at', three_hour_ago_str) \
            .lte('created_at', current_time_str) \
            .order('pub_date', desc=True) \
            .execute()
            
        logger.info(f"Found {len(response.data) if hasattr(response, 'data') else 0} new articles")
        
        news_count = len(response.data) if hasattr(response, 'data') else 0
        logger.info(f"Fetched {news_count} news items for today")
        
        return response.data if hasattr(response, 'data') else []
        
    except Exception as e:
        logger.error(f"Error fetching today's news: {str(e)}", exc_info=True)
        return []

def summarize_with_ai(texts: List[str], category: str, max_retries: int = 2) -> Optional[str]:
    """
    Together.ai APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.
    
    Args:
        texts: ìš”ì•½í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        category: ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬
        max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        
    Returns:
        str: ìš”ì•½ëœ í…ìŠ¤íŠ¸ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
    """
    logger.info(f"Starting summarization for category: {category}")
    
    if not texts:
        logger.warning("No text provided for summarization")
        return None
        
    # API í‚¤ ë¡œë“œ
    api_key = os.getenv("TOGETHER_API_KEY")
    if not api_key:
        logger.error("TOGETHER_API_KEY not found in environment variables")
        return None
    
    # ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ë¡œ ê²°í•© (ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ ì¡°ì ˆ)
    combined_text = "\n".join(texts[:10])
    if len(combined_text) > 4000:
        logger.debug(f"Truncating text from {len(combined_text)} to 4000 characters")
        combined_text = combined_text[:4000]
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = f"""'{category}' ì¹´í…Œê³ ë¦¬ì˜ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì…ë‹ˆë‹¤. 
ì´ ë‰´ìŠ¤ë“¤ì˜ ì£¼ìš” ë‚´ìš©ì„ 3-5ê°œì˜ í•µì‹¬ í¬ì¸íŠ¸ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
ê° í¬ì¸íŠ¸ëŠ” ê°„ê²°í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

{combined_text}

ìš”ì•½:
1. """
    
    logger.debug(f"Generated prompt for category: {category}")
    
    for attempt in range(max_retries + 1):
        try:
            logger.info(f"Attempt {attempt + 1}/{max_retries + 1} - Sending request to Together.ai")
            
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": "meta-llama/Llama-3-8b-chat-hf",
                "prompt": prompt,
                "max_tokens": 500,
                "temperature": 0.7,
                "top_p": 0.9
            }
            
            # API ìš”ì²­ ì‹œê°„ ì¸¡ì •
            start_time = time.time()
            
            response = requests.post(
                "https://api.together.xyz/v1/completions",
                headers=headers,
                json=payload,
                timeout=60  # 60ì´ˆ íƒ€ì„ì•„ì›ƒ
            )
            
            elapsed = time.time() - start_time
            logger.debug(f"API response received in {elapsed:.2f} seconds")
            
            if response.status_code == 200:
                result = response.json()
                logger.debug(f"API response: {result}")
                
                if 'choices' in result and len(result['choices']) > 0:
                    generated_text = result['choices'][0]['text'].strip()
                    logger.debug(f"Generated text length: {len(generated_text)} characters")
                    
                    # ìœ íš¨ì„± ê²€ì‚¬: [INST] íƒœê·¸ê°€ ìˆìœ¼ë©´ ì¬ì‹œë„
                    if '[INST]' in generated_text or '[/INST]' in generated_text:
                        if attempt < max_retries:
                            logger.warning(f"Invalid response format detected, retrying... ({attempt + 1}/{max_retries})")
                            time.sleep(1)  # ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
                            continue
                        else:
                            logger.warning("Max retries reached with invalid format")
                    
                    # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
                    generated_text = generated_text.replace('[/INST]', '').replace('[INST]', '').strip()
                    
                    # ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” í¬ì¸íŠ¸ë§Œ í•„í„°ë§
                    points = []
                    for line in generated_text.split('\n'):
                        line = line.strip()
                        if line and (line[0].isdigit() or line.startswith('-')):
                            # ë¼ì¸ì—ì„œ ìˆ«ì/ë¶ˆë¦¿ ì´í›„ì˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                            point = line[line.find('.') + 1:].strip() if '.' in line else line[1:].strip()
                            if point and len(point) > 3:  # ìµœì†Œ ê¸¸ì´ ê²€ì‚¬
                                points.append(point)
                    
                    logger.info(f"Extracted {len(points)} valid points from response")
                    
                    if points:  # ìœ íš¨í•œ í¬ì¸íŠ¸ê°€ ìˆìœ¼ë©´ ë°˜í™˜
                        summary = '\n'.join(points[:5])
                        logger.info(f"Successfully generated summary with {len(points)} points")
                        return summary
                    
                    # í¬ì¸íŠ¸ê°€ ì—†ìœ¼ë©´ ì¬ì‹œë„
                    if attempt < max_retries:
                        logger.warning(f"No valid points found, retrying... ({attempt + 1}/{max_retries})")
                        time.sleep(1)  # ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
                        continue
                        
            else:
                logger.error(f"API request failed: {response.status_code} - {response.text}")
                if response.status_code >= 500:  # ì„œë²„ ì—ëŸ¬ì¸ ê²½ìš°ì—ë§Œ ì¬ì‹œë„
                    if attempt < max_retries:
                        time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                        continue
                
        except requests.exceptions.RequestException as e:
            logger.error(f"Request error during summarization (attempt {attempt + 1}): {str(e)}")
            if attempt < max_retries:
                time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                continue
        except Exception as e:
            logger.error(f"Unexpected error during summarization (attempt {attempt + 1}): {str(e)}", exc_info=True)
            if attempt < max_retries:
                time.sleep(1)
                continue
    
    logger.warning(f"Failed to generate summary for category: {category} after {max_retries + 1} attempts")
    return None

def normalize_text(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤.
    - íŠ¹ìˆ˜ë¬¸ì ì œê±°
    - ê³µë°± ì •ê·œí™”
    - ì†Œë¬¸ì ë³€í™˜
    
    Args:
        text: ì •ê·œí™”í•  í…ìŠ¤íŠ¸
        
    Returns:
        str: ì •ê·œí™”ëœ í…ìŠ¤íŠ¸
    """
    import re
    # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    text = re.sub(r'[^\w\s]', ' ', text)
    # ê³µë°± ì •ê·œí™”
    text = ' '.join(text.split())
    # ì†Œë¬¸ì ë³€í™˜
    return text.lower()

def remove_source_suffix(text: str) -> str:
    """
    ë‰´ìŠ¤ ì œëª©ì—ì„œ ì¶œì²˜ ì •ë³´ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
    ì˜ˆ: 'ì œëª© - ì¶œì²˜' -> 'ì œëª©'
    
    Args:
        text: ì²˜ë¦¬í•  í…ìŠ¤íŠ¸
        
    Returns:
        str: ì¶œì²˜ê°€ ì œê±°ëœ í…ìŠ¤íŠ¸
    """
    # ' - ' ë˜ëŠ” ' | ' ë˜ëŠ” ' : 'ë¡œ ë¶„ë¦¬í•˜ì—¬ ì²« ë²ˆì§¸ ë¶€ë¶„ë§Œ ì·¨í•¨
    for sep in [' - ', ' | ', ' : ']:
        if sep in text:
            text = text.split(sep)[0].strip()
    return text

def calculate_similarity(str1: str, str2: str) -> float:
    """
    ë‘ ë¬¸ìì—´ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ 0~1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        str1: ì²« ë²ˆì§¸ ë¬¸ìì—´
        str2: ë‘ ë²ˆì§¸ ë¬¸ìì—´
        
    Returns:
        float: 0~1 ì‚¬ì´ì˜ ìœ ì‚¬ë„ ì ìˆ˜ (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬í•¨)
    """
    # ì›ë³¸ ìœ ì‚¬ë„
    original_similarity = difflib.SequenceMatcher(None, str1, str2).ratio()
    
    # ì¶œì²˜ ì œê±° í›„ ìœ ì‚¬ë„
    clean_str1 = remove_source_suffix(str1)
    clean_str2 = remove_source_suffix(str2)
    clean_similarity = difflib.SequenceMatcher(None, clean_str1, clean_str2).ratio()
    
    # ì •ê·œí™”ëœ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„
    norm_str1 = normalize_text(clean_str1)
    norm_str2 = normalize_text(clean_str2)
    norm_similarity = difflib.SequenceMatcher(None, norm_str1, norm_str2).ratio()
    
    # ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ ë°˜í™˜
    return max(original_similarity, clean_similarity, norm_similarity)

def analyze_tech_trends(news_items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    ë‰´ìŠ¤ ì•„ì´í…œì„ ë¶„ì„í•˜ì—¬ ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        news_items: ë¶„ì„í•  ë‰´ìŠ¤ ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        List[Dict[str, Any]]: ì¶”ì¶œëœ ê¸°ìˆ  íŠ¸ë Œë“œ ë¦¬ìŠ¤íŠ¸
    """
    # ê¸°ìˆ  í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ ì •ì˜
    tech_categories = {
        'AI/ML': ['AI', 'ë¨¸ì‹ ëŸ¬ë‹', 'ë”¥ëŸ¬ë‹', 'ì¸ê³µì§€ëŠ¥', 'LLM', 'GPT', 'ëª¨ë¸', 'í•™ìŠµ', 'ì¶”ë¡ ', 'ìƒì„±í˜• AI'],
        'í´ë¼ìš°ë“œ': ['í´ë¼ìš°ë“œ', 'AWS', 'GCP', 'Azure', 'ì„œë²„ë¦¬ìŠ¤', 'ë„ì»¤', 'ì¿ ë²„ë„¤í‹°ìŠ¤', 'ì¸í”„ë¼', 'DevOps'],
        'ì›¹/ëª¨ë°”ì¼': ['ì›¹', 'ëª¨ë°”ì¼', 'ì•±', 'í”„ë¡ íŠ¸ì—”ë“œ', 'ë°±ì—”ë“œ', 'API', 'í”„ë ˆì„ì›Œí¬', 'React', 'Next.js', 'Vue', 'Flutter'],
        'ë°ì´í„°': ['ë°ì´í„°', 'ë¶„ì„', 'ë¹…ë°ì´í„°', 'ë°ì´í„°ë² ì´ìŠ¤', 'SQL', 'NoSQL', 'ë²¡í„°DB', 'RAG', 'ETL']
    }
    
    # ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ì´ˆê¸°í™”
    category_scores = {category: defaultdict(int) for category in tech_categories}
    
    # ë‰´ìŠ¤ ì•„ì´í…œ ë¶„ì„
    for item in news_items:
        title = item.get('title', '')
        description = item.get('description', '')
        content = f"{title} {description}"
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì ìˆ˜ ê³„ì‚°
        for category, keywords in tech_categories.items():
            score = sum(content.count(keyword) for keyword in keywords)
            if score > 0:
                # ì¶œì²˜ ìˆ˜ì§‘ì„ ìœ„í•´ ì•„ì´í…œ ID ì €ì¥
                if 'items' not in category_scores[category]:
                    category_scores[category]['items'] = []
                category_scores[category]['items'].append(item)
                category_scores[category]['score'] += score
    
    # ìƒìœ„ íŠ¸ë Œë“œ ì¶”ì¶œ
    trends = []
    for category, data in category_scores.items():
        if 'items' in data and data['items']:
            # ëŒ€í‘œ ì•„ì´í…œ ì„ íƒ (ê°€ì¥ ìµœê·¼ ì•„ì´í…œ)
            latest_item = max(data['items'], key=lambda x: x.get('pub_date', ''))
            
            # ê°„ë‹¨í•œ ìš”ì•½ ìƒì„±
            title = latest_item.get('title', '')
            source = latest_item.get('source', 'ì¶œì²˜ ì—†ìŒ')
            
            # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ í‚¤ ìƒì„±
            trend_key = f"{category}_{title[:30]}"
            
            trends.append({
                'category': category,
                'title': title,
                'description': latest_item.get('description', ''),
                'source': source,
                'score': data['score'],
                'key': trend_key,
                'url': latest_item.get('url', '#')
            })
    
    # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬ ë° ì¤‘ë³µ ì œê±°
    seen = set()
    unique_trends = []
    for trend in sorted(trends, key=lambda x: x['score'], reverse=True):
        if trend['key'] not in seen:
            seen.add(trend['key'])
            unique_trends.append(trend)
    
    return unique_trends[:4]  # ìƒìœ„ 4ê°œë§Œ ë°˜í™˜

def remove_duplicate_news(news_items: List[Dict[str, Any]], similarity_threshold: float = 0.75) -> List[Dict[str, Any]]:
    """
    ì œëª©ì˜ ìœ ì‚¬ë„ê°€ ë†’ì€ ì¤‘ë³µ ë‰´ìŠ¤ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
    
    Args:
        news_items: ë‰´ìŠ¤ ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸
        similarity_threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (0~1), ì´ ê°’ë³´ë‹¤ ë†’ìœ¼ë©´ ì¤‘ë³µìœ¼ë¡œ íŒë‹¨
        
    Returns:
        List[Dict[str, Any]]: ì¤‘ë³µì´ ì œê±°ëœ ë‰´ìŠ¤ ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸
    """
    if not news_items:
        return []
        
    # ì¶œì²˜ ì •ë³´ê°€ ë” ê¸´ ë‰´ìŠ¤ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ìœ ì§€í•˜ê¸° ìœ„í•´ ì •ë ¬
    sorted_news = sorted(news_items, 
                        key=lambda x: len(x.get('title', '')), 
                        reverse=True)
    
    unique_news = []
    seen_titles = []
    removed_count = 0
    
    for item in sorted_news:
        title = item.get('title', '').strip()
        if not title:
            continue
            
        is_duplicate = False
        
        # ì¶œì²˜ ì œê±°ëœ ì œëª©ìœ¼ë¡œ ë¹„êµ
        clean_title = remove_source_suffix(title)
        
        # ì´ë¯¸ ë³¸ ì œëª©ë“¤ê³¼ ìœ ì‚¬ë„ ë¹„êµ
        for seen_item in unique_news:
            seen_title = seen_item.get('title', '').strip()
            seen_clean = remove_source_suffix(seen_title)
            
            # ì¶œì²˜ê°€ ë‹¤ë¥¸ ê²½ìš°ì—ë§Œ ìœ ì‚¬ë„ ì²´í¬
            if clean_title != seen_clean:
                similarity = calculate_similarity(title, seen_title)
                if similarity > similarity_threshold:
                    is_duplicate = True
                    removed_count += 1
                    logger.info(f"Removing duplicate article (similarity: {similarity:.2f}):\n  - Original: {seen_title}\n  - Duplicate: {title}")
                    break
        
        if not is_duplicate:
            unique_news.append(item)
    
    logger.info(f"Removed {removed_count} duplicate articles (kept {len(unique_news)} unique articles)")
    return unique_news

def format_newsletter() -> Optional[str]:
    """
    Supabaseì˜ newsletter_sections í…Œì´ë¸”ì—ì„œ ì˜¤ëŠ˜ ë‚ ì§œì˜ ì„¹ì…˜ë“¤ì„ ê°€ì ¸ì™€ ë‰´ìŠ¤ë ˆí„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Returns:
        str: ìƒì„±ëœ HTML ë‰´ìŠ¤ë ˆí„° ë˜ëŠ” None
    """
    # KST ê¸°ì¤€ ì˜¤ëŠ˜ ë‚ ì§œ (YYYY-MM-DD)
    today_kst = datetime.now().strftime('%Y-%m-%d')
    logger.info(f"Fetching newsletter sections for date: {today_kst}")
    
    try:
        # Supabaseì—ì„œ ì˜¤ëŠ˜ ë‚ ì§œì˜ ì„¹ì…˜ ì¡°íšŒ (is_published=Trueì¸ í•­ëª©ë§Œ)
        response = supabase.table('newsletter_sections') \
            .select('*') \
            .eq('publish_date', today_kst) \
            .eq('is_published', True) \
            .order('display_order') \
            .execute()
        
        sections = response.data if hasattr(response, 'data') else []
        
        if not sections:
            logger.info(f"No published sections found for date: {today_kst}")
            return None
            
        logger.info(f"Found {len(sections)} sections for today's newsletter")
        
        # HTML ìƒì„±
        html_content = f"""
        <div style="font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px;">
            <h1 style="color: #1a365d;">ğŸ“° AI ë‰´ìŠ¤ë ˆí„° - {today_kst}</h1>
            <p style="color: #4a5568;">AI ë¶„ì•¼ì˜ ìµœì‹  ì†Œì‹ê³¼ ì¸ì‚¬ì´íŠ¸ë¥¼ ì „í•´ë“œë¦½ë‹ˆë‹¤.</p>
        """
        
        # ì„¹ì…˜ë³„ ë Œë”ë§
        for section in sections:
            section_name = section.get('section_name', '')
            section_title = section.get('section_title', '')
            content = section.get('content', [])
            summary = section.get('summary', '')
            
            if not content or not isinstance(content, list):
                logger.warning(f"Skipping section {section_name} - invalid content format")
                continue
                
            # ì„¹ì…˜ í—¤ë”
            html_content += f"""
            <div style="margin-top: 30px; padding: 20px; background-color: #f9fafb; border-radius: 8px;">
                <h2 style="color: #2d3748; border-bottom: 2px solid #e2e8f0; padding-bottom: 10px;">
                    {section_title}
                </h2>
            """
            
            # ìš”ì•½ì´ ìˆëŠ” ê²½ìš° í‘œì‹œ
            if summary:
                html_content += f"""
                <div style="background: #edf2f7; padding: 12px 15px; border-radius: 6px; margin-bottom: 15px; font-size: 0.95em; line-height: 1.5; color: #2d3748;">
                    {summary}
                </div>
                """
            
            # ì½˜í…ì¸  í•­ëª©ë“¤
            html_content += """
                <div style="margin-top: 15px;">
                    <ul style="list-style: none; padding: 0; margin: 0;">
            """
            
            # ê° ì½˜í…ì¸  í•­ëª© ë Œë”ë§
            for item in content:
                if not isinstance(item, dict):
                    continue
                    
                title = item.get('title', '')
                url = item.get('url', '#')
                description = item.get('description', '')
                source = item.get('source', '')
                
                html_content += f"""
                <li style="margin-bottom: 20px; background: white; padding: 18px; border-radius: 8px; box-shadow: 0 2px 6px rgba(0,0,0,0.05);">
                    <a href="{url}" target="_blank" style="color: #2563eb; font-weight: 600; font-size: 1.05em; text-decoration: none; line-height: 1.4; display: block; margin-bottom: 8px;">
                        {title}
                    </a>
                """
                
                if description:
                    html_content += f"""
                    <p style="color: #4b5563; margin: 8px 0 10px 0; line-height: 1.5; font-size: 0.95em;">
                        {description}
                    </p>
                    """
                
                if source:
                    html_content += f"""
                    <div style="display: flex; justify-content: space-between; align-items: center; margin-top: 10px;">
                        <span style="color: #6b7280; font-size: 0.85em;">{source}</span>
                    </div>
                    """
                
                html_content += "</li>"
            
            # ì„¹ì…˜ ë‹«ê¸°
            html_content += """
                    </ul>
                </div>
            </div>
            """
        
        # í‘¸í„°
        html_content += f"""
        <div style="margin-top: 40px; padding-top: 20px; border-top: 1px solid #e5e7eb; color: #6b7280; font-size: 0.9em;">
            <p>ì´ ë‰´ìŠ¤ë ˆí„°ëŠ” {today_kst} ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.</p>
            <p style="margin-top: 10px;">ë‰´ìŠ¤ë ˆí„° êµ¬ë…ì„ ì›í•˜ì§€ ì•Šìœ¼ì‹œë©´ <a href="#" style="color: #4f46e5;">ì—¬ê¸°</a>ë¥¼ í´ë¦­í•´ êµ¬ë…ì„ ì·¨ì†Œí•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
        </div>
        </div>
        """
        
        return html_content
        
    except Exception as e:
        logger.error(f"Error formatting newsletter: {str(e)}", exc_info=True)
        return None

    return html_content



def send_newsletter():
    """
    ë‰´ìŠ¤ë ˆí„°ë¥¼ ì´ë©”ì¼ë¡œ ë°œì†¡í•©ë‹ˆë‹¤.
    
    Returns:
        bool: ì´ë©”ì¼ ë°œì†¡ ì„±ê³µ ì—¬ë¶€
    """
    logger.info("Starting newsletter sending process...")
    
    # ìˆ˜ì‹ ì ì´ë©”ì¼ ì£¼ì†Œ í™•ì¸
    recipient_email = os.getenv("RECIPIENT_EMAIL", "tlstjscjswo@gmail.com")
    if not recipient_email:
        logger.error("No recipient email address found")
        return False
    
    logger.info(f"Preparing to send newsletter to: {recipient_email}")
    
    # ë‰´ìŠ¤ë ˆí„° HTML ìƒì„±
    logger.info("Generating newsletter HTML content...")
    html_content = format_newsletter()
    
    if not html_content:
        logger.error("No HTML content generated for the newsletter")
        return False
    
    logger.debug(f"Generated HTML content length: {len(html_content)} characters")
    
    # ì´ë©”ì¼ ì œëª© ì„¤ì • (ì‹œê°„ëŒ€ í‘œì‹œ)
    current_time = datetime.now()
    email_subject = f"ğŸ¤– AI/LLM ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ - {current_time.strftime('%m/%d %H:%M')} ê¸°ì¤€"
    
    try:
        logger.info("Sending email via Resend API...")
        
        # ì´ë©”ì¼ ë°œì†¡ ìš”ì²­
        response = resend.Emails.send({
            "from": "AI Newsletter <onboarding@resend.dev>",
            "to": [recipient_email],
            "subject": email_subject,
            "html": html_content
        })
        
        # ì‘ë‹µ ë¡œê¹…
        if isinstance(response, dict) and 'id' in response:
            logger.info(f"Email sent successfully! Email ID: {response['id']}")
            return True
        else:
            logger.error(f"Unexpected response from Resend API: {response}")
            return False
            
    except Exception as e:
        if hasattr(e, 'status_code'):
            logger.error(f"Resend API error (HTTP {e.status_code}): {str(e)}")
        else:
            logger.error(f"Resend API error: {str(e)}")
        return False
    except Exception as e:
        logger.error(f"Unexpected error while sending email: {str(e)}", exc_info=True)
        return False

if __name__ == "__main__":
    try:
        logger.info("=" * 50)
        logger.info("Starting AI Newsletter Sender")
        logger.info(f"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("=" * 50)
        
        # Send the newsletter
        success = send_newsletter()
        
        if success:
            logger.info("Newsletter sent successfully!")
        else:
            logger.error("Failed to send newsletter")
            
    except KeyboardInterrupt:
        logger.warning("Process interrupted by user")
    except Exception as e:
        logger.critical(f"Critical error in main execution: {str(e)}", exc_info=True)
    finally:
        logger.info("=" * 50)
        logger.info(f"Process completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("=" * 50)
